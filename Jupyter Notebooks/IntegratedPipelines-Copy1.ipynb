{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and loading the csv file\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean = pd.read_csv(r\"C:\\Users\\91886\\OneDrive\\QMUL Masterclass\\vehicles_initialdatacleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean = pd.DataFrame(vehicles_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean = vehicles_clean.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bdaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean['description'] = vehicles_clean['description'].astype('string')\n",
    "# Replace 'other' with 1 and strip 'cylinders' string from other values\n",
    "vehicles_clean['cylinders'] = vehicles_clean['cylinders'].str.replace('other', '1').str.rstrip('cylinders').str.strip()\n",
    "# Convert to float data type and replace '<NA>' values with NaN\n",
    "vehicles_clean['cylinders'] = pd.to_numeric(vehicles_clean['cylinders'], errors='coerce').astype(float)\n",
    "# drop model and posting_date column for encoding\n",
    "vehicles_clean.drop(['condition','id','posting_date','model'], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# define the features and target variables\n",
    "X = vehicles_clean.drop('price', axis=1)\n",
    "y = vehicles_clean['price']\n",
    "\n",
    "# divide the data into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# display the shapes of the resulting datasets\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1d9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class TokenizerTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Convert to lowercase\n",
    "        X = X.apply(lambda x: x.lower())\n",
    "        # Tokenize into words\n",
    "        X = X.apply(lambda x: word_tokenize(x)[:3500])  # Limit tokens to 3500\n",
    "        # Remove stop words\n",
    "        stop_words = stopwords.words('english')\n",
    "        X = X.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "        # Lemmatize words using WordNetLemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        X = X.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "        # Remove punctuation\n",
    "        X = X.apply(lambda x: [word for word in x if word not in string.punctuation])\n",
    "        # Return tokenized text\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline with for tokenization\n",
    "token_pipeline = Pipeline([\n",
    "    ('tokenizer', TokenizerTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9827920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['description'] = token_pipeline.fit_transform(X_train['description'])\n",
    "X_val['description'] = token_pipeline.transform(X_val['description'])\n",
    "X_test['description'] = token_pipeline.transform(X_test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73493c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vehicles_clean['description'] = token_pipeline.fit_transform(vehicles_clean['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7fbce9",
   "metadata": {},
   "source": [
    "# Cylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7438d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predefined lists\n",
    "# Define the list of valid cylinders\n",
    "cylinder_list = ['i2','i3','i4','i5','i6','i8','i10','i12',\n",
    "                 'v2','v3','v4','v5','v6','v8','v10','v12', \n",
    "                 '2cylinder','3cylinder','4cylinder','5cylinder','6cylinder','8cylinder','10cylinder','12cylinder',\n",
    "                 '2cylinders','3cylinders','4cylinders','5cylinders','6cylinders','8cylinders','10cylinders',\n",
    "                '12cylinders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90914c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CylindersCleaning(BaseEstimator, TransformerMixin):\n",
    "# ReplaceNaNWithCylinders    \n",
    "    def __init__(self, cylinder_list):\n",
    "        self.cylinder_list = cylinder_list\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "# replace_nan_with_cylinder        \n",
    "        def cylinders_cleaning(row):\n",
    "            cylinders = row['cylinders']\n",
    "            desc = row['description']\n",
    "            if pd.isnull(cylinders):\n",
    "                for c in self.cylinder_list:\n",
    "                    if c in desc:\n",
    "                        stripped_c = c.strip('ivcylinders')\n",
    "                        try:\n",
    "                            cylinders = float(stripped_c)\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "            row['cylinders'] = cylinders\n",
    "            return row\n",
    "        \n",
    "        X = X.apply(cylinders_cleaning, axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efc850",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyl_pipeline = Pipeline([\n",
    "    ('cylinders_cleaning', CylindersCleaning(cylinder_list)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e0ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = cyl_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    '''select specific columns of a given dataset'''\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b356243",
   "metadata": {},
   "outputs": [],
   "source": [
    "cylclean_pipeline = Pipeline(steps=[('replace_cylinders', CylindersCleaning(cylinder_list)),\n",
    "                           ('ct', ColumnTransformer(transformers=[('imputer', SimpleImputer(strategy='mean'), \n",
    "                                                                   ['cylinders'])],remainder='passthrough'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cylinders'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = cylclean_pipeline.fit_transform(X_train)\n",
    "# X_val_t = cylclean_pipeline.transform(X_val)\n",
    "# X_test_t = cylclean_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_t, columns=X_train.columns)\n",
    "# X_val = pd.DataFrame(X_val_t, columns=X_val.columns)\n",
    "# X_test = pd.DataFrame(X_test_t, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd41b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cylinders'].isna().sum()\n",
    "X_val['cylinders'].isna().sum()\n",
    "X_test['cylinders'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a95a7",
   "metadata": {},
   "source": [
    "# Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed327a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split drive\n",
    "class SplitDrive(TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        X_new = []\n",
    "        for row in X:\n",
    "            new_row = []\n",
    "            for val in row:\n",
    "                if 'drive' in val:\n",
    "                    split_vals = val.split('drive')\n",
    "                    for i in range(len(split_vals)):\n",
    "                        if i == 0:\n",
    "                            new_row.append(split_vals[i])\n",
    "                        elif i == len(split_vals) - 1:\n",
    "                            if split_vals[i] != '':\n",
    "                                if new_row[-1] == '':\n",
    "                                    new_row.pop()\n",
    "                                new_row.append('drive')\n",
    "                                new_row.append(split_vals[i])\n",
    "                            else:\n",
    "                                new_row.append('drive')\n",
    "                        elif split_vals[i] != '':\n",
    "                            if new_row[-1] == '':\n",
    "                                new_row.pop()\n",
    "                            new_row.extend(['drive', split_vals[i]])\n",
    "                else:\n",
    "                    new_row.append(val)\n",
    "            X_new.append(new_row)\n",
    "        return X_new\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b021d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First level of cleaning - check for 2 drive occurences \n",
    "class DriveImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mapping_dict = {'two wheel': 'rwd', 'all wheel': '4wd', '2 wheel': 'rwd', '4 wheel': '4wd','four wheel': '4wd',\n",
    "                            'awd':'4wd','4x4':'4wd','xdrive':'4wd','quattro':'4wd'}\n",
    "        self.drive_master = ['rwd','4wd','awd','xdrive','4x4','4matic','fwd','quattro']\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        nan_rows = X['drive'].isnull()\n",
    "        X.loc[nan_rows, 'drive'] = X.loc[nan_rows, 'description'].apply(lambda x: self.get_drive(x))\n",
    "        X['drive'] = X['drive'].map(self.mapping_dict).fillna(X['drive'])\n",
    "        X['drive'] = X['drive'].apply(lambda x: self.check_drive(x))\n",
    "        return X\n",
    "        \n",
    "    def get_drive(self, description):\n",
    "        drive_idxs = [i for i, x in enumerate(description) if x == 'drive']\n",
    "        if len(drive_idxs) >= 2:\n",
    "            start_idx = drive_idxs[0]\n",
    "            end_idx = drive_idxs[1]\n",
    "            drive = ' '.join(description[start_idx+1:end_idx]).lower()\n",
    "            return drive\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    def check_drive(self, drive):\n",
    "        if drive in self.drive_master:\n",
    "            return drive\n",
    "        else:\n",
    "            return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second level of cleaning - check for first drive occurence\n",
    "\n",
    "\n",
    "class DriveTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # list of possible drive values\n",
    "        drive_master = ['rwd', '4wd', 'awd', 'xdrive', '4x4', '4matic', 'fwd','awdtransmission','quattro']\n",
    "        # dictionary mapping common drive phrases to standard values\n",
    "        mapping_dict = {'two wheel': 'rwd', 'all wheel': '4wd', '2 wheel': 'rwd', \n",
    "                        '4 wheel': '4wd', 'four wheel': '4wd', 'awd': '4wd','awdtransmission':'4wd',\n",
    "                       '4x4':'4wd','4x4':'4wd','xdrive':'4wd','quattro':'4wd'}\n",
    "    \n",
    "        # loop through the rows of the dataframe\n",
    "        for i, row in X.iterrows():\n",
    "            # check if the 'drive' value is NaN\n",
    "            if pd.isna(row['drive']):\n",
    "                # loop through the 'description' list to find the first occurrence of 'drive'\n",
    "                if 'drive' in row['description']:\n",
    "                    j = row['description'].index('drive')\n",
    "                    # if 'drive' is found, replace the NaN value with the next non-empty token in the list\n",
    "                    for k in range(j+1, len(row['description'])):\n",
    "                        if row['description'][k] != '':\n",
    "                            # check if the token is in the drive_master list\n",
    "                            if row['description'][k] in drive_master:\n",
    "                                # map the token to the standard value using the mapping_dict\n",
    "                                X.at[i, 'drive'] = mapping_dict.get(row['description'][k], row['description'][k])\n",
    "                            break\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dee22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import YearTransformer\n",
    "year_transformer = YearTransformer()\n",
    "drive_imputer = DriveImputer()\n",
    "vehicles_clean = year_transformer.fit_transform(vehicles_clean)\n",
    "vehicles_clean = drive_imputer.fit_transform(vehicles_clean)\n",
    "clean_data = pipeline.fit_transform(vehicles_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('split_drive', SplitDrive()),\n",
    "    ('impute_drive', DriveImputer()),\n",
    "    ('transform_drive', DriveTransformer())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a09a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriveImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mapping_dict = {'4wd': 'four_wheel_drive',\n",
    "                             'fwd': 'front_wheel_drive',\n",
    "                             'rwd': 'rear_wheel_drive',\n",
    "                             'awd': 'all_wheel_drive'}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = pd.DataFrame(X)  # Convert X to a pandas DataFrame\n",
    "        nan_rows = X['drive'].isnull()\n",
    "        X.loc[nan_rows, 'drive'] = X.loc[nan_rows, 'description'].apply(lambda x: self.get_drive(x))\n",
    "        X['drive'] = X['drive'].map(self.mapping_dict).fillna(X['drive'])\n",
    "        return X.values.tolist()  # Convert X back to a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb80295",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pipeline.fit_transform(vehicles_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1f3c3",
   "metadata": {},
   "source": [
    "# Paint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d964e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['description'].iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc99053",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['description'].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitExteriorInterior(TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        X_new = []\n",
    "        for row in X:\n",
    "            new_row = []\n",
    "            for val in row:\n",
    "                if 'exterior' in val:\n",
    "                    split_vals = val.split('exterior')\n",
    "                    for i in range(len(split_vals)):\n",
    "                        if i == 0:\n",
    "                            new_row.append(split_vals[i])\n",
    "                        elif i == len(split_vals) - 1:\n",
    "                            if split_vals[i] != '':\n",
    "                                if new_row[-1] == '':\n",
    "                                    new_row.pop()\n",
    "                                new_row.append('exterior')\n",
    "                                new_row.append(split_vals[i])\n",
    "                            else:\n",
    "                                new_row.append('exterior')\n",
    "                        elif split_vals[i] != '':\n",
    "                            if new_row[-1] == '':\n",
    "                                new_row.pop()\n",
    "                            new_row.extend(['exterior', split_vals[i]])\n",
    "                elif 'interior' in val:\n",
    "                    split_vals = val.split('interior')\n",
    "                    for i in range(len(split_vals)):\n",
    "                        if i == 0:\n",
    "                            new_row.append(split_vals[i])\n",
    "                        elif i == len(split_vals) - 1:\n",
    "                            if split_vals[i] != '':\n",
    "                                if new_row[-1] == '':\n",
    "                                    new_row.pop()\n",
    "                                new_row.append('interior')\n",
    "                                new_row.append(split_vals[i])\n",
    "                            else:\n",
    "                                new_row.append('interior')\n",
    "                        elif split_vals[i] != '':\n",
    "                            if new_row[-1] == '':\n",
    "                                new_row.pop()\n",
    "                            new_row.extend(['interior', split_vals[i]])\n",
    "                else:\n",
    "                    new_row.append(val)\n",
    "            X_new.append(new_row)\n",
    "        return X_new\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6625b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ext_int_pipeline = Pipeline([\n",
    "    ('split_ext_int', SplitExteriorInterior())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba4942",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean['description'] = split_ext_int_pipeline.fit_transform(vehicles_clean['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['description'] = split_ext_int_pipeline.fit_transform(X_train['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['description'].iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['description'] = split_ext_int_pipeline.transform(X_val['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aace624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['description'].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6560c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['description'] = split_ext_int_pipeline.transform(X_test['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4caad",
   "metadata": {},
   "source": [
    "## paint_color cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc3cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "paint_master = ['white', 'blue', 'red', 'black', 'silver', 'grey', 'beige','brown', 'burgundy', \n",
    "               'gold', 'yellow', 'orange', 'green','purple', 'tan', 'charcoal','anvil', \n",
    "               'maroon','gray','champagne','olive','darkblue','darkgreen','lightblue','lightgray',\n",
    "               'lightgrey','darkgray','darkgrey','teal','sapphireblue','midnightbblue','charcoalgray',\n",
    "               'bronze','copper','pearlwhite','pearlblack','rossored','brilliantsilve','cyan','magenta',\n",
    "                'aliceblue','antiquewhite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6fbc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'gray':'grey','whiteinterior':'white','brilliantsilve':'silver','pearlwhite':'white',\n",
    "                'darkgray':'grey','lightgray':'grey','sapphireblue':'blue','darkblue':'blue','lightblue':'blue',\n",
    "               'darkgreen':'green','aliceblue':'blue','antiquewhite':'white'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e90236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class PaintColorImputer(TransformerMixin):\n",
    "    def __init__(self, paint_master, mapping_dict):\n",
    "        self.paint_master = paint_master\n",
    "        self.mapping_dict = mapping_dict\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_new = X.copy()\n",
    "        for i, row in X_new.iterrows():\n",
    "            if pd.isna(row['paint_color']):\n",
    "                description_tokens = row['description']\n",
    "                try:\n",
    "                    color_token_idx = description_tokens.index('color')\n",
    "                    if 'exterior' in description_tokens[color_token_idx-1]:\n",
    "                        color = description_tokens[color_token_idx+1]\n",
    "                        if color in self.paint_master:\n",
    "                            if color in self.mapping_dict:\n",
    "                                X_new.at[i, 'paint_color'] = self.mapping_dict[color]\n",
    "                            else:\n",
    "                                X_new.at[i, 'paint_color'] = color\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "        return X_new\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b3603",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('paint_color_imputer', PaintColorImputer(paint_master, mapping_dict))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183cc66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean['paint_color'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean = pipeline.fit_transform(vehicles_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de55ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean['paint_color'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d060030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color_pipeline = Pipeline([\n",
    "#     ('paint_color_imputer', PaintColorImputer(paint_master, mapping_dict))\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675bda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    '''select specific columns of a given dataset'''\n",
    "    def __init__(self, subset):\n",
    "        self.subset = subset\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.loc[:, self.subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdca642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_pipeline = Pipeline(steps=[('paint_color_imputer', PaintColorImputer(paint_master, mapping_dict)),\n",
    "#                            ('ct', ColumnTransformer(transformers=[('imputer', SimpleImputer(strategy='mean'), \n",
    "#                                                                    ['paint_color'])],remainder='passthrough'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline(steps=[\n",
    "    ('paint_color_imputer', PaintColorImputer(paint_master, mapping_dict)),\n",
    "    ('ct', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent'), ['paint_color'])], \n",
    "        remainder='drop'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253c42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean['paint_color'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean = full_pipeline.fit_transform(vehicles_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean['paint_color'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57edf277",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('paint_color_imputer', PaintColorImputer(paint_master, mapping_dict)),\n",
    "                           ('ct', ColumnTransformer(transformers=[('imputer', SimpleImputer(strategy='most_frequent'), \n",
    "                                                                   ['paint_color'])],remainder='passthrough'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff0889",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean_t = pipeline.fit_transform(vehicles_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba7eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean_t = pd.DataFrame(vehicles_clean_t, columns=vehicles_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f99e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles_clean_t['paint_color'].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
